{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_TqzUruQJrP"
      },
      "source": [
        "# Szum w Etykietach Danych\n",
        "\n",
        "![label_noise_intro.png](https://live.staticflickr.com/65535/54328952408_f7e5bcb7c9_z.jpg)\n",
        "\n",
        "*Obraz wygenerowany przy użyciu modelu generatywnego z OpenArt.ai.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbULc5cmrh-R"
      },
      "source": [
        "## Wstęp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXap1DBercbC"
      },
      "source": [
        "Kluczowe w uczeniu maszynowym są dane. Od nich wszystko się zaczyna. W praktyce jednak dane często nie są idealne i zawierają pewien szum zmieniejszający ich jakość. Jednym z rodzajów takiego szumu jest szum w etykietach danych, co oznacza, że dla niektórych obserwacji etykiety są niepoprawne.\n",
        "\n",
        "Przyczyny szumu w etykietach mogą być zróżnicowane. Często wynikają one z subiektywności oceny – różni eksperci mogą mieć odmienne zdanie, np. oceniając emocje na zdjęciach lub jakość wypracowania. Innym źródłem błędów może być zmęczenie anotatorów, które wpływa na ich koncentrację i dokładność.\n",
        "\n",
        "Niejasności mogą też wynikać ze słabej jakości danych, która utrudnia jednoznaczną klasyfikację (np. rozmyte zdjęcie psa, który przypomina wilka). Czasem etykiety bywają generowane automatycznie przez modele sztucznej inteligencji, które również mogą popełniać błędy.\n",
        "\n",
        "Warto wspomnieć o próbkach znajdujących się na granicy klas. Takie przypadki, np. w danych medycznych, gdzie objawy są zbliżone dla różnych chorób, również prowadzą do trudności w przypisaniu jednoznacznej etykiety.\n",
        "\n",
        "Zaszumienie danych utrudnia wytrenowanie modelu o dobrej jakości, ponieważ model może skupić się bardziej na niepoprawnych informacjach niż na ogólnych regułach w nich zawartych."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVGwSAIprjLb"
      },
      "source": [
        "## Zadanie\n",
        "\n",
        "Twoim zadaniem będzie wytrenowanie **dwóch** sieci neuronowych do poprawnej binarnej klasyfikacji obrazów pomimo częściowego zaszumienia etykiet w danych treningowych. Zbiór treningowy jest niezbalansowany (weź to pod uwagę w swoim rozwiązaniu). Zbiór walidacyjny jak i testowy (który będzie użyty do ewaluacji Twojego finalnego rozwiązania) mają tylko poprawne etykiety (bez szumu).\n",
        "\n",
        "**Architektura modeli jest zdefiniowana i nie możesz jej zmieniać.**\n",
        "\n",
        "Zastanów się dlaczego korzystamy z dwóch modeli a nie jednego (to jest pewna zagadka) - to pomoże Ci zrozumieć zadanie i je rozwiązać.\n",
        "Twoją rolą w tym zadaniu jest zaimplementować funkcję `your_selected_indices(targets, losses)`, która wybierze indeksy danych ze zbioru treningowego, które zostaną wykorzystane do trenowania modeli. Funkcja przyjmuje na wejściu tensor z etykietami danych (`targets`) i tensor z wartościami funkcji straty z obu modeli (`losses`). Wynikiem tej funkcji powininna być dwuelementowa lista, gdzie elementami będą tensory zawierające indeksy wybrane do trenowania modeli. Jeden model otrzymuje jeden zestaw indeksów, drugi model otrzymuje drugi.\n",
        "Poniżej w notatniku znajdziesz komórkę, w której znajduje się miejsce na Twoją funkcję. Komórka, którą powinieneś zmodyfikować jest wyraźnie oznaczona. Żeby lepiej zrozumieć jej działanie i cel warto zobaczyć kontekst i miejsce gdzie ta funkcja zostanie wywołana w pętli treningowej.\n",
        "\n",
        "### Kryterium Oceny\n",
        "Ostateczna ocena zadania będzie na podstawie średniej wartości zbalansowanej miary trafności (*ang. balanced accuracy, BAC*) z dwóch modeli tj. ${BAC}_{mean} = \\frac{BAC_1+BAC_2}{2}$ gdzie $BAC_i$ to *balanced accuracy* dla modelu $i$, ($i = 1, 2$).\n",
        "\n",
        "Za to zadanie możesz zdobyć pomiędzy 0 a 100 punktów.\n",
        "\n",
        "Twój finalny wynik punktowy za rozwiązanie zadania obliczony będzie według poniższej funkcji (im wyższa wartość tym lepiej) przy dodatkowym zastosowaniu zakrąglenia do wartości całkowitych:\n",
        "$$\n",
        "\\mathrm{Punkty} =\n",
        "\\begin{cases}\n",
        "    0 & \\text{jeżeli } {BAC}_{mean} \\leq 0.5 \\\\\n",
        "    100 \\times \\frac{{BAC}_{mean} - 0.5}{0.8 - 0.5} & \\text{jeżeli } 0.5 < {BAC}_{mean} < 0.8 \\\\\n",
        "    100 & \\text{jeżeli } {BAC}_{mean} \\geq 0.8\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "**Uwaga: Zauważ, że żeby zdobyć maksymalną ilość punktów nie ma konieczności osiągnięcia maksymalnej wartości *balanced accuracy* równej 1. Jeśli ${BAC}_{mean}$ będzie równe co najmniej 0.8, wówczas otrzymasz maksymalną liczbę punktów.**\n",
        "\n",
        "To kryterium i wszystkie funkcje, o których mowa powyżej, są zaimplementowane poniżej przez nas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pah3rtnOrr7h"
      },
      "source": [
        "## Ograniczenia\n",
        "\n",
        "- Twoje rozwiazanie będzie testowane na Platformie Konkursowej bez dostępu do internetu oraz w środowisku z GPU.\n",
        "- Ewaluacja Twojego finalnego rozwiązania na Platformie Konkursowej nie może trwać dłużej niż 5 minut z GPU.\n",
        "- **Nie możesz** zmieniać architektury modeli - musi to być zdefiniowany przez nas `SmallMobileNet`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f0E2NDlrwhF"
      },
      "source": [
        "## Pliki zgłoszeniowe\n",
        "Ten notebook uzupełniony o Twoje rozwiązanie (patrz funkcja `your_selected_indices`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYF5fUxJr1BX"
      },
      "source": [
        "## Ewaluacja\n",
        "Pamiętaj, że podczas sprawdzania flaga `FINAL_EVALUATION_MODE` zostanie ustawiona na `True`.\n",
        "\n",
        "Za to zadanie możesz zdobyć pomiędzy 0 a 100 punktów. Liczba punktów, którą zdobędziesz, będzie wyliczona na (tajnym) zbiorze testowym na Platformie Konkursowej na podstawie wyżej wspomnianego wzoru, zaokrąglona do liczby całkowitej. Jeśli Twoje rozwiązanie nie będzie spełniało powyższych kryteriów lub nie będzie wykonywać się prawidłowo, otrzymasz za zadanie 0 punktów."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2bmpToSr4JS"
      },
      "source": [
        "# Kod Startowy\n",
        "W tej sekcji inicjalizujemy środowisko poprzez zaimportowanie potrzebnych bibliotek i funkcji. Przygotowany kod ułatwi Tobie efektywne operowanie na danych i budowanie właściwego rozwiązania."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mDrJx8xMsCOe"
      },
      "outputs": [],
      "source": [
        "# W czasie sprawdzania Twojego rozwiązania, wartość flagi FINAL_EVALUATION_MODE zostanie zmieniona na True\n",
        "FINAL_EVALUATION_MODE = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1vTKKO7dsEaN"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from typing import Optional, Tuple, List\n",
        "\n",
        "import zipfile\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets.folder import VisionDataset\n",
        "\n",
        "from sklearn.metrics import balanced_accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KL_LMSNKA0CT"
      },
      "source": [
        "## Funkcje i Stałe Pomocnicze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "stkLXG_NAPgc"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "SEED = 123\n",
        "IMAGES_DIR = \"data\"\n",
        "TASK_DATASET_LABELS_FILE = \"dataset_labels.csv\"\n",
        "\n",
        "ROOT_DIR = os.getcwd()\n",
        "TRAIN_DATASET_PATH = os.path.join(ROOT_DIR,'train')\n",
        "VAL_DATASET_PATH = os.path.join(ROOT_DIR, 'val')\n",
        "\n",
        "TRAIN_DATASET_URL = \"1qmNNmDv-wUcAv5mvO6vYJV3mQ2SNIGnI\"\n",
        "VAL_DATASET_URL = \"1YUJYD12NmKRSzFJGMrX-a61d6mnTaWbG\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_BBm56joD-Si",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df0a9209-c4eb-493f-b736-7b28608255bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "LEARNING_RATE = 1e-2\n",
        "NUM_EPOCHS = 6\n",
        "NUM_CLASSES = 2\n",
        "BATCH_SIZE = 128\n",
        "WEIGHT_DECAY = 1e-3\n",
        "\n",
        "if not FINAL_EVALUATION_MODE:\n",
        "  print(f\"Using {DEVICE} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MuAhda77vDuI"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "def seed_everything(seed: int) -> None:\n",
        "    \"\"\"\n",
        "    Ustawia ziarno (seed) dla odtwarzalności wyników w Pythonie, NumPy oraz PyTorch.\n",
        "\n",
        "    Funkcja ustawia ziarno dla generatorów liczb losowych Pythonie, NumPy oraz PyTorch,\n",
        "    a także konfiguruje PyTorch do pracy w trybie deterministycznym.\n",
        "\n",
        "    Parametry:\n",
        "        seed (int): Wartość ziarna do ustawienia.\n",
        "    \"\"\"\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8ONQLgUA2vj"
      },
      "source": [
        "## Ładowanie Danych\n",
        "Za pomocą poniższego kodu dane zostaną wczytane i odpowiednio przygotowane."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VudHqvfDHtka"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "def download_data(dataset_path, dataset_url):\n",
        "    \"\"\"Pobiera zbiór danych z Google Drive Olimpiady i zapisuje go w folderze.\"\"\"\n",
        "    import gdown\n",
        "    import shutil\n",
        "\n",
        "    # Utwórz lub zresetuj folder\n",
        "    output = dataset_path+\".zip\"\n",
        "    if os.path.exists(dataset_path):\n",
        "        shutil.rmtree(dataset_path)\n",
        "    if os.path.exists(output):\n",
        "        os.remove(output)\n",
        "\n",
        "    url = f'https://drive.google.com/uc?id={dataset_url}'\n",
        "    gdown.download(url, output, fuzzy=True)\n",
        "\n",
        "    print(f\"Downloaded: {output}\")\n",
        "\n",
        "# Pobierz dane tylko jeśli nie jesteś w trybie FINAL_EVALUATION_MODE\n",
        "if not FINAL_EVALUATION_MODE:\n",
        "    download_data(TRAIN_DATASET_PATH, TRAIN_DATASET_URL)\n",
        "    download_data(VAL_DATASET_PATH, VAL_DATASET_URL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O263pNeBAbCF"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "# Klasa zbioru danych\n",
        "class TaskDataset(VisionDataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        root: str,\n",
        "        transform: Optional[callable] = None,\n",
        "    ):\n",
        "        super().__init__(\n",
        "            root,\n",
        "            transform=transform,\n",
        "        )\n",
        "        self.root = root\n",
        "\n",
        "        if not self._check_integrity():\n",
        "            raise RuntimeError(\n",
        "                f\"Nie znaleziono zbioru danych. Sprawdź czy ścieżka {self.root} istnieje. Powinna ona zwierać folder '{IMAGES_DIR}' i plik '{TASK_DATASET_LABELS_FILE}' file\"\n",
        "            )\n",
        "        self.labels_df = self._read_labels_from_file()\n",
        "        self.labels_header = 'label'\n",
        "\n",
        "    def _read_labels_from_file(self) -> pd.DataFrame:\n",
        "        df = pd.read_csv(os.path.join(self.root, TASK_DATASET_LABELS_FILE))\n",
        "        return df\n",
        "\n",
        "    def _check_integrity(self) -> bool:\n",
        "        return os.path.exists(os.path.join(self.root, IMAGES_DIR)) and os.path.exists(\n",
        "            os.path.join(self.root, TASK_DATASET_LABELS_FILE)\n",
        "        )\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.labels_df)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[Image.Image, np.ndarray]:\n",
        "        img = self._load_image(idx)\n",
        "        label = self._load_label(idx)\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "    def _load_image(self, idx: int) -> Image.Image:\n",
        "        img_path = os.path.join(\n",
        "            self.root, IMAGES_DIR, self.labels_df.iloc[idx]['file_name']\n",
        "        )\n",
        "        img = Image.open(img_path)\n",
        "        return img\n",
        "\n",
        "    def _load_label(self, idx: int):\n",
        "        label = self.labels_df.iloc[idx][self.labels_header]\n",
        "        return np.array([int(label)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsoOe-u1wANO"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "def unpack_data(unpack_path, dataset_name) -> None:\n",
        "    dataset_zip_path = os.path.join(ROOT_DIR, dataset_name+\".zip\")\n",
        "    dataset_local_dir = os.path.join(unpack_path, dataset_name)\n",
        "    if not os.path.exists(dataset_local_dir):\n",
        "        if not os.path.exists(dataset_zip_path):\n",
        "            raise FileNotFoundError(\n",
        "                f\"Nie znaleziono pliku {dataset_zip_path} w bieżącym folderze.\"\n",
        "            )\n",
        "\n",
        "        with zipfile.ZipFile(dataset_zip_path, \"r\") as zip_ref:\n",
        "            zip_ref.extractall(unpack_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTkEhPtYA799"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "# Funkcja ładująca dane treningowe i walidacyjne\n",
        "def load_data() -> Tuple[DataLoader, DataLoader]:\n",
        "    \"\"\"\n",
        "    Funkcja ładująca dane treningowe i walidacyjne przy użyciu klasy TaskDataset.\n",
        "\n",
        "    Funkcja tworzy zbiory danych dla danych treningowych oraz walidacyjnych,\n",
        "    stosuje podstawową transformację (konwersję do tensora), a następnie\n",
        "    opakowuje je w obiekty DataLoader.\n",
        "\n",
        "    Zwraca:\n",
        "        Tuple[DataLoader, DataLoader]: Obiekty DataLoader dla zbioru treningowego oraz walidacyjnego.\n",
        "    \"\"\"\n",
        "    base_transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "    train_dataset = TaskDataset(root=TRAIN_DATASET_PATH, transform=base_transform)\n",
        "    val_dataset = TaskDataset(root=VAL_DATASET_PATH, transform=base_transform)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=False\n",
        "    )\n",
        "    val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    return train_loader, val_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqHpbHVfhb5N"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "# Rozpakujmy i załadujmy dane\n",
        "if not FINAL_EVALUATION_MODE:\n",
        "    unpack_data(ROOT_DIR, \"train\")\n",
        "    unpack_data(ROOT_DIR, \"val\")\n",
        "    train_loader, val_loader = load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDTOKmvwB4Ai"
      },
      "source": [
        "## Architektura Modelu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qkxih_KVAj54"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "class SmallMobileNet(nn.Module):\n",
        "    def __init__(self, num_classes=NUM_CLASSES):\n",
        "        super(SmallMobileNet, self).__init__()\n",
        "\n",
        "        # Główne bloki konwolucyjne\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU6(inplace=True),\n",
        "            nn.Conv2d(\n",
        "                32, 32, kernel_size=3, stride=1, padding=1, groups=32, bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU6(inplace=True),\n",
        "            nn.Conv2d(32, 64, kernel_size=1, stride=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU6(inplace=True),\n",
        "            nn.Conv2d(\n",
        "                64, 64, kernel_size=3, stride=2, padding=1, groups=64, bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU6(inplace=True),\n",
        "            nn.Conv2d(64, 128, kernel_size=1, stride=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU6(inplace=True),\n",
        "            nn.Conv2d(\n",
        "                128, 128, kernel_size=3, stride=2, padding=1, groups=128, bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU6(inplace=True),\n",
        "            nn.Conv2d(128, 256, kernel_size=1, stride=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU6(inplace=True),\n",
        "        )\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU6(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Mu9eZAgpKQM"
      },
      "source": [
        "## Kod z Kryterium Oceniającym\n",
        "\n",
        "Kod, zbliżony do poniższego, będzie używany do oceny rozwiązania na zbiorze testowym."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4APzhbt9BE3h"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "def predict_and_evaluate(model, val_loader, device, verbose=False):\n",
        "    model.eval()\n",
        "    all_preds, all_targets = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in val_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_targets.extend(targets.cpu().numpy())\n",
        "\n",
        "    balanced_accuracy = balanced_accuracy_score(all_targets, all_preds)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Balanced Accuracy: {balanced_accuracy}\")\n",
        "\n",
        "    return balanced_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jd5RQhtepPQo"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "def performance(bac_1: float, bac_2: float) -> None:\n",
        "    \"\"\"\n",
        "    Oblicza i wypisuje wynik wydajności na podstawie dwóch wartości balanced accuracy.\n",
        "\n",
        "    Ostateczny wynik to średnia z obu wartości, przeskalowana między ustalonymi granicami,\n",
        "    co przekłada się na liczbę zdobytych punktów.\n",
        "\n",
        "    Parametry:\n",
        "        bac_1 (float): Wartość balanced accuracy dla pierwszego modelu.\n",
        "        bac_2 (float): Wartość balanced accuracy dla drugiego modelu.\n",
        "    \"\"\"\n",
        "    bac_mean = (bac_1 + bac_2) / 2\n",
        "    if bac_mean <= 0.5:\n",
        "        points = 0\n",
        "    elif 0.5 < bac_mean < 0.8:\n",
        "        points = (bac_mean - 0.5) / (0.8 - 0.5) * 100\n",
        "        points = int(round(points))\n",
        "    else:\n",
        "        points = 100\n",
        "\n",
        "    print(\n",
        "        f\"Twoje rozwiązanie ma średnią wartość balanced accuracy równą {round(bac_mean, 5)} na zbiorze walidacyjnym, co daje {points}/100 punktów.\"\n",
        "    )\n",
        "    return points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idShIZwfjzAr"
      },
      "source": [
        "## Trening Modelu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpnzpyhnxxVC"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "\n",
        "# Funkcja do trenowania modelu\n",
        "def train(\n",
        "    model1,\n",
        "    model2,\n",
        "    optimizer1,\n",
        "    optimizer2,\n",
        "    criterion,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    num_epochs,\n",
        "    device,\n",
        "    select_indices_fn,\n",
        "):\n",
        "\n",
        "    verbose = False if FINAL_EVALUATION_MODE else True\n",
        "\n",
        "    # Historia metryk dla każdego modelu\n",
        "    metrics = {\n",
        "        k: [[], []]\n",
        "        for k in [\n",
        "            \"train_loss\",\n",
        "            \"val_loss\",\n",
        "            \"train_bac\",\n",
        "            \"val_bac\",\n",
        "        ]\n",
        "    }\n",
        "    epochs_range = np.arange(num_epochs) + 1\n",
        "\n",
        "    # Główna pętla treningowa\n",
        "    for epoch in epochs_range:\n",
        "        print(f\"Epoch {epoch}\")\n",
        "\n",
        "        # Historia statystyk dla każdego modelu\n",
        "        stats = {\n",
        "            k: [0, 0] for k in [\"train_loss\", \"train_total\", \"val_loss\", \"val_total\"]\n",
        "        }\n",
        "        preds_targets = {\n",
        "            k: [[], []]\n",
        "            for k in [\"train_preds\", \"train_targets\", \"val_preds\", \"val_targets\"]\n",
        "        }\n",
        "\n",
        "        model1.train(), model2.train()\n",
        "        for inputs, targets in tqdm(train_loader, desc=f\"Epoch {epoch}/{num_epochs}\"):\n",
        "            inputs, targets = inputs.to(device), targets.squeeze().long().to(device)\n",
        "\n",
        "            outputs = [m(inputs) for m in (model1, model2)]\n",
        "            losses = [criterion(out, targets) for out in outputs]\n",
        "\n",
        "            # --- GŁÓWNY PUNKT ZADANIA ---\n",
        "            selected_indices = select_indices_fn(targets, losses)\n",
        "            # ---------------------------\n",
        "\n",
        "            # Propagacja wsteczna dla każdego modelu\n",
        "            for i, (model, optim) in enumerate(\n",
        "                [(model1, optimizer1), (model2, optimizer2)]\n",
        "            ):\n",
        "                optim.zero_grad()\n",
        "                sel_idx = selected_indices[i]\n",
        "                loss = criterion(model(inputs[sel_idx]), targets[sel_idx]).mean()\n",
        "\n",
        "                loss.backward()\n",
        "                optim.step()\n",
        "\n",
        "                # Historia statystyk\n",
        "                stats[\"train_loss\"][i] += loss.item() * len(sel_idx)\n",
        "                stats[\"train_total\"][i] += len(sel_idx)\n",
        "                preds = outputs[i].max(1)[1]\n",
        "                preds_targets[\"train_preds\"][i].extend(preds[sel_idx].cpu().numpy())\n",
        "                preds_targets[\"train_targets\"][i].extend(targets[sel_idx].cpu().numpy())\n",
        "\n",
        "        # Ewaluacja na zbiorze walidacyjnym\n",
        "        if verbose:\n",
        "            model1.eval(), model2.eval()\n",
        "            with torch.no_grad():\n",
        "                for inputs, targets in tqdm(\n",
        "                    val_loader, desc=f\"Validation {epoch}/{num_epochs}\"\n",
        "                ):\n",
        "                    inputs, targets = inputs.to(device), targets.squeeze().long().to(\n",
        "                        device\n",
        "                    )\n",
        "\n",
        "                    for i, model in enumerate([model1, model2]):\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, targets).mean()\n",
        "                        preds = outputs.max(1)[1]\n",
        "\n",
        "                        stats[\"val_loss\"][i] += loss.item() * inputs.size(0)\n",
        "                        stats[\"val_total\"][i] += inputs.size(0)\n",
        "                        preds = outputs.max(1)[1]\n",
        "                        preds_targets[\"val_preds\"][i].extend(preds.cpu().numpy())\n",
        "                        preds_targets[\"val_targets\"][i].extend(targets.cpu().numpy())\n",
        "\n",
        "        # Obliczanie metryk\n",
        "        if verbose:\n",
        "            models = [model1, model2]\n",
        "            for i in range(2):\n",
        "                for phase in [\"train\", \"val\"]:\n",
        "                    preds = preds_targets[f\"{phase}_preds\"][i]\n",
        "                    targets = preds_targets[f\"{phase}_targets\"][i]\n",
        "\n",
        "                    metrics[f\"{phase}_loss\"][i].append(\n",
        "                        stats[f\"{phase}_loss\"][i] / stats[f\"{phase}_total\"][i]\n",
        "                    )\n",
        "                    metrics[f\"{phase}_bac\"][i].append(\n",
        "                        balanced_accuracy_score(targets, preds)\n",
        "                    )\n",
        "\n",
        "                print(\n",
        "                    f\"Model{i+1} - Train Loss: {metrics['train_loss'][i][-1]:.4f}, \"\n",
        "                    f\"Train balanced accuracy: {metrics['train_bac'][i][-1]:.4f} --- \"\n",
        "                    f\"Validation Loss: {metrics['val_loss'][i][-1]:.4f}, \"\n",
        "                    f\"Validation balanced accuracy: {metrics['val_bac'][i][-1]:.4f}, \"\n",
        "                )\n",
        "\n",
        "    # Generowanie wykresów\n",
        "    if verbose:\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "        colors = [\"#fa2729\", \"#ac1a1c\", \"#1a6aff\", \"#144aad\"]\n",
        "        linestyles = [\"-\", \"--\"]\n",
        "\n",
        "        for i, model_name in enumerate([\"Model1\", \"Model2\"]):\n",
        "            for j, phase in enumerate([\"train\", \"val\"]):\n",
        "\n",
        "                color = colors[i * 2 + j]\n",
        "                ax1.plot(\n",
        "                    epochs_range,\n",
        "                    metrics[f\"{phase}_loss\"][i],\n",
        "                    color=color,\n",
        "                    marker=\"o\",\n",
        "                    linestyle=linestyles[j],\n",
        "                    label=f\"{model_name} {phase.title()} Loss\",\n",
        "                )\n",
        "                ax2.plot(\n",
        "                    epochs_range,\n",
        "                    metrics[f\"{phase}_bac\"][i],\n",
        "                    color=color,\n",
        "                    marker=\"o\",\n",
        "                    linestyle=linestyles[j],\n",
        "                    label=f\"{model_name} {phase.title()} balanced accuracy\",\n",
        "                )\n",
        "\n",
        "        for ax, title in zip([ax1, ax2], [\"Loss\", \"Balanced accuracy\"]):\n",
        "            ax.set_title(f\"Training and Validation {title}\")\n",
        "            ax.set_xticks(epochs_range)\n",
        "            ax.set_xlabel(\"Epochs\")\n",
        "            ax.set_ylabel(title)\n",
        "            ax.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7uonc2-mCak"
      },
      "source": [
        "## Przykładowe Rozwiązanie\n",
        "Poniżej przedstawiamy uproszczone rozwiązanie, które służy jako przykład demonstrujący podstawową funkcjonalność notatnika. Może ono posłużyć jako punkt wyjścia do opracowania Twojego rozwiązania."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOI8Venajwal"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "def default_select_indices(targets, losses):\n",
        "    # Wszystkie indeksy dla obu modeli\n",
        "    selected_indices = [torch.arange(targets.shape[0]).to(DEVICE) for _ in range(2)]\n",
        "    return selected_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3Btb8AY0hD0"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "# WAŻNE: Trenujemy zawsze dwa modele i ewaluujemy\n",
        "\n",
        "if not FINAL_EVALUATION_MODE:\n",
        "    seed_everything(SEED)\n",
        "    criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "\n",
        "    model1 = SmallMobileNet(NUM_CLASSES).to(DEVICE)\n",
        "    model2 = SmallMobileNet(NUM_CLASSES).to(DEVICE)\n",
        "\n",
        "    optimizer1 = AdamW(model1.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "    optimizer2 = AdamW(model2.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "    seed_everything(SEED)\n",
        "    train(\n",
        "        model1,\n",
        "        model2,\n",
        "        optimizer1,\n",
        "        optimizer2,\n",
        "        criterion,\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        NUM_EPOCHS,\n",
        "        DEVICE,\n",
        "        select_indices_fn=default_select_indices,\n",
        "    )\n",
        "\n",
        "    # Ewaluacja przykładowego rozwiązania\n",
        "    bac_1 = predict_and_evaluate(model1, val_loader, DEVICE, verbose=True)\n",
        "    bac_2 = predict_and_evaluate(model2, val_loader, DEVICE, verbose=True)\n",
        "\n",
        "    performance(bac_1, bac_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GLrTYyoqhJT"
      },
      "source": [
        "# Twoje Rozwiązanie\n",
        "W tej sekcji należy umieścić Twoje rozwiązanie. Wprowadzaj zmiany wyłącznie tutaj!\n",
        "\n",
        "Aktualnie startowym rozwiązaniem jest to przykładowe. Twoim zadaniem jest zmodyfikowanie wnętrza (ciała) funkcji. W rozwiązaniu nie korzystaj z `default_select_indices`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNMjWrAvqldU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from typing import List\n",
        "\n",
        "def your_select_indices(targets: torch.Tensor, losses: List[torch.Tensor]) -> List[torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Funkcja wybierająca indeksy zbioru treningowego do wykorzystania podczas trenowania modeli.\n",
        "\n",
        "    Parametry:\n",
        "        targets: Etykiety danych treningowych z danego batcha jako tensor. Wymiar: (batch_size,)\n",
        "        losses: Dwuelementowa lista zawierająca tensory wartości funkcji straty dla poszczególnych modeli. Wymiar: [(batch_size,), (batch_size,)]\n",
        "\n",
        "    Zwraca:\n",
        "        Listę indeksów wybranych do aktualizacji wag modeli.\n",
        "    \"\"\"\n",
        "    # Twój kod\n",
        "    rozmiar_batcha = targets.size(0)\n",
        "\n",
        "\n",
        "    indeksy_klasy_0 = (targets == 0).nonzero(as_tuple=True)[0]\n",
        "    indeksy_klasy_1 = (targets == 1).nonzero(as_tuple=True)[0]\n",
        "\n",
        "\n",
        "    srednie_straty = (losses[0] + losses[1]) / 2.0\n",
        "\n",
        "\n",
        "    if len(indeksy_klasy_0) > 0:\n",
        "        straty_klasy_0 = srednie_straty[indeksy_klasy_0]\n",
        "        posortowane_klasy_0 = indeksy_klasy_0[torch.argsort(straty_klasy_0)]\n",
        "        prog_0 = max(1, int(len(posortowane_klasy_0) * 0.8))\n",
        "        zaufane_klasy_0 = posortowane_klasy_0[:prog_0]\n",
        "        niezaufane_klasy_0 = posortowane_klasy_0[prog_0:]\n",
        "        model0_niezaufane_0 = niezaufane_klasy_0[losses[0][niezaufane_klasy_0] < losses[1][niezaufane_klasy_0]]\n",
        "        model1_niezaufane_0 = niezaufane_klasy_0[losses[0][niezaufane_klasy_0] >= losses[1][niezaufane_klasy_0]]\n",
        "    else:\n",
        "        zaufane_klasy_0 = torch.tensor([], dtype=torch.long, device=targets.device)\n",
        "        model0_niezaufane_0 = torch.tensor([], dtype=torch.long, device=targets.device)\n",
        "        model1_niezaufane_0 = torch.tensor([], dtype=torch.long, device=targets.device)\n",
        "\n",
        "    if len(indeksy_klasy_1) > 0:\n",
        "        straty_klasy_1 = srednie_straty[indeksy_klasy_1]\n",
        "        posortowane_klasy_1 = indeksy_klasy_1[torch.argsort(straty_klasy_1)]\n",
        "        prog_1 = max(1, int(len(posortowane_klasy_1) * 0.8))\n",
        "        zaufane_klasy_1 = posortowane_klasy_1[:prog_1]\n",
        "        niezaufane_klasy_1 = posortowane_klasy_1[prog_1:]\n",
        "        model0_niezaufane_1 = niezaufane_klasy_1[losses[0][niezaufane_klasy_1] < losses[1][niezaufane_klasy_1]]\n",
        "        model1_niezaufane_1 = niezaufane_klasy_1[losses[0][niezaufane_klasy_1] >= losses[1][niezaufane_klasy_1]]\n",
        "    else:\n",
        "        zaufane_klasy_1 = torch.tensor([], dtype=torch.long, device=targets.device)\n",
        "        model0_niezaufane_1 = torch.tensor([], dtype=torch.long, device=targets.device)\n",
        "        model1_niezaufane_1 = torch.tensor([], dtype=torch.long, device=targets.device)\n",
        "\n",
        "\n",
        "    indeksy_modelu_0 = torch.cat([\n",
        "        zaufane_klasy_0, zaufane_klasy_1,\n",
        "        model0_niezaufane_0, model0_niezaufane_1\n",
        "    ])\n",
        "\n",
        "    indeksy_modelu_1 = torch.cat([\n",
        "        zaufane_klasy_0, zaufane_klasy_1,\n",
        "        model1_niezaufane_0, model1_niezaufane_1\n",
        "    ])\n",
        "\n",
        "    return [indeksy_modelu_0, indeksy_modelu_1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgwPClAjVqPZ"
      },
      "source": [
        "# Ewaluacja\n",
        "\n",
        "Uruchomienie poniższych komórek pozwoli sprawdzić, ile punktów zdobyłoby Twoje rozwiązanie na danych walidacyjnych. Przed wysłaniem upewnij się, że cały notebook (również z ustawioną flagą `FINAL_EVALUATION_MODE = True`) wykonuje się od początku do końca bez błędów i bez konieczności ingerencji użytkownika po wybraniu opcji \"Run All\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCmm0PK2pw14"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "def final_evaluate(evaluate_data_path, model1, model2):\n",
        "\n",
        "    base_transform = transforms.Compose([transforms.ToTensor()])\n",
        "    evaluate_dataset = TaskDataset(root=evaluate_data_path, transform=base_transform)\n",
        "    evaluate_loader = DataLoader(\n",
        "        dataset=evaluate_dataset, batch_size=BATCH_SIZE, shuffle=False\n",
        "    )\n",
        "\n",
        "    bac_1 = predict_and_evaluate(model1, evaluate_loader, DEVICE, verbose=True)\n",
        "    bac_2 = predict_and_evaluate(model2, evaluate_loader, DEVICE, verbose=True)\n",
        "    return performance(bac_1, bac_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZySGvI7-HNk"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "if not FINAL_EVALUATION_MODE:\n",
        "    seed_everything(SEED)\n",
        "    criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "\n",
        "    model1 = SmallMobileNet(NUM_CLASSES).to(DEVICE)\n",
        "    model2 = SmallMobileNet(NUM_CLASSES).to(DEVICE)\n",
        "\n",
        "    optimizer1 = AdamW(model1.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "    optimizer2 = AdamW(model2.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "    seed_everything(SEED)\n",
        "    train(\n",
        "        model1,\n",
        "        model2,\n",
        "        optimizer1,\n",
        "        optimizer2,\n",
        "        criterion,\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        NUM_EPOCHS,\n",
        "        DEVICE,\n",
        "        select_indices_fn=your_select_indices,\n",
        "    )\n",
        "\n",
        "    final_evaluate(VAL_DATASET_PATH, model1, model2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj2dU2V5aSIS"
      },
      "source": [
        "Twoja funkcja `your_select_indices` zostanie zapisana do pliku `your_select_indices.pkl`, a następnie wykorzystana do trenowania modeli na zbiorze treningowym (zgodnie z powyższym kodem). Finalna liczba punktów zostanie wyliczona na podstawie jakości klasyfikacji na zbiorze testowym."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDqcb6DGo4vw"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "if FINAL_EVALUATION_MODE:\n",
        "    import cloudpickle\n",
        "\n",
        "    OUTPUT_PATH = \"file_output\"\n",
        "    FUNCTION_FILENAME = \"your_select_indices.pkl\"\n",
        "    FUNCTION_OUTPUT_PATH = os.path.join(OUTPUT_PATH, FUNCTION_FILENAME)\n",
        "\n",
        "    if not os.path.exists(OUTPUT_PATH):\n",
        "        os.makedirs(OUTPUT_PATH)\n",
        "\n",
        "    with open(FUNCTION_OUTPUT_PATH, \"wb\") as f:\n",
        "        cloudpickle.dump(your_select_indices, f)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}